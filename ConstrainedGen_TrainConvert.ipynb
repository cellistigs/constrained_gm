{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing pipeline to turn generated data into a format that is easy to read into tensorflow: TFRecord files.\n",
    "# These files allow for fast read and write to Tensorflow architectures, and are preferred using the new Dataset API. \n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "import numpy\n",
    "import glob\n",
    "from skimage.transform import resize\n",
    "import sys\n",
    "\n",
    "# The documentation for this code is somewhat spotty, and has been cobbled together from a variety of sources:\n",
    "# https://medium.com/@WuStangDan/step-by-step-tensorflow-object-detection-api-tutorial-part-2-converting-dataset-to-tfrecord-47f24be9248d\n",
    "# http://machinelearninguru.com/deep_learning/tensorflow/basics/tfrecord/tfrecord.html\n",
    "# https://www.skcript.com/svr/why-every-tensorflow-developer-should-know-about-tfrecord/\n",
    "# tensorflow/inception/inception/data/build_image_Data.py\n",
    "\n",
    "# Once within the format of tfrecord files, it is easier to combine datasets, to split them, etc, so we just treat\n",
    "# these on a video by video basis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Designate helper function to define features for examples more easily\n",
    "def _int64_feature_(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def _bytes_feature_(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "def _full_example_(videoname,reader,i):\n",
    "    img_0 = reader.get_data(i)\n",
    "    img_0_ds = resize(img_0,(128,128))\n",
    "\n",
    "    features = {'video': _bytes_feature_(tf.compat.as_bytes((videoname))),\n",
    "                'frame': _int64_feature_(i),\n",
    "                'image': _bytes_feature_(tf.compat.as_bytes(img_0_ds.tostring())),\n",
    "                }\n",
    "    example = tf.train.Example(features = tf.train.Features(feature = features))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on video: datadirectory/toydynamics_nograv/Video_ball_color.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taigaabe/anaconda3/envs/constrainedgen/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on video: datadirectory/toydynamics_nograv/Video_ball_color_noback.mp4\n",
      "working on video: datadirectory/toydynamics_nograv/Video_ball_color_big.mp4\n"
     ]
    }
   ],
   "source": [
    "# We iterate through all directories\n",
    "videos = glob.glob('datadirectory/toydynamics_nograv/*.mp4')\n",
    "for videoname in videos:\n",
    "    print('working on video: ' +videoname)\n",
    "    # Choose a video, and load it\n",
    "    video = imageio.get_reader(videoname,'ffmpeg')\n",
    "    # We want to open a corresponding tfRecords file\n",
    "    datafile_name = videoname.split('.mp4')[0]+'train.tfrecords'\n",
    "    writer = tf.python_io.TFRecordWriter(datafile_name)\n",
    "    nb_frames = video.get_length()\n",
    "    for i in range(nb_frames):\n",
    "        # Iterate through frames\n",
    "        example = _full_example_(videoname,video,i)\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constrainedgm",
   "language": "python",
   "name": "constrainedgm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
